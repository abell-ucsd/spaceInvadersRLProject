{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.1 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==2.3.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.1 gym keras-rl2 gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ale-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Test Random Environment with OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/SpaceInvaders-v5\")#, render_mode=\"rgb_array\"\n",
    "#env.metadata[\"render_fps\"] = 120\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gym\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython import display\n",
    "from skimage import io\n",
    "#from skimage.color import rgb2grey\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import deque, namedtuple\n",
    "plt.style.use('seaborn')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, num_frames, num_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.num_frames = num_frames\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=num_frames,\n",
    "            out_channels=16,\n",
    "            kernel_size=8,\n",
    "            stride=4,\n",
    "            padding=2\n",
    "            )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "            )\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=3200,\n",
    "            out_features=256,\n",
    "            )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=256,\n",
    "            out_features=num_actions,\n",
    "            )\n",
    "        \n",
    "        # Activation Functions\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Forward pass\n",
    "        x = self.relu(self.conv1(x))  # In: (80, 80, 4)  Out: (20, 20, 16)\n",
    "        x = self.relu(self.conv2(x))  # In: (20, 20, 16) Out: (10, 10, 32)\n",
    "        x = self.flatten(x)           # In: (10, 10, 32) Out: (3200,)\n",
    "        x = self.relu(self.fc1(x))    # In: (3200,)      Out: (256,)\n",
    "        x = self.fc2(x)               # In: (256,)       Out: (4,)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f41376b86d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transition = namedtuple('Transition', ['state', 'action', 'reward', 'terminal', 'next_state'])\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, memory_depth, lr, gamma, epsilon_i, epsilon_f, anneal_time, ckptdir):\n",
    "        \n",
    "        self.cuda = True if torch.cuda.is_available() else False\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = torch.device(\"cuda\" if self.cuda else \"cpu\")\n",
    "        \n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        \n",
    "        self.memory_depth = memory_depth\n",
    "        self.gamma = torch.tensor([gamma], device=self.device)\n",
    "        self.e_i = epsilon_i\n",
    "        self.e_f = epsilon_f\n",
    "        self.anneal_time = anneal_time\n",
    "        self.ckptdir = ckptdir\n",
    "        \n",
    "        if not os.path.isdir(ckptdir):\n",
    "            os.makedirs(ckptdir)\n",
    "        \n",
    "        self.memory = deque(maxlen=memory_depth)\n",
    "        self.clone()\n",
    "        \n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "        self.opt = torch.optim.RMSprop(self.model.parameters(), lr=lr, alpha=0.95, eps=0.01)\n",
    "        \n",
    "    def clone(self):\n",
    "        try:\n",
    "            del self.clone_model\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.clone_model = copy.deepcopy(self.model)\n",
    "        \n",
    "        for p in self.clone_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        if self.cuda:\n",
    "            self.clone_model = self.clone_model.cuda()\n",
    "    \n",
    "    def remember(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    \n",
    "    def retrieve(self, batch_size):\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        state, action, reward, terminal, next_state = map(torch.cat, [*batch])\n",
    "        return state, action, reward, terminal, next_state\n",
    "    \n",
    "    @property\n",
    "    def memories(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def act(self, state):\n",
    "        q_values = self.model(state).detach()\n",
    "        action = torch.argmax(q_values)\n",
    "        return action.item()\n",
    "    \n",
    "    def process(self, state):\n",
    "        #state=np.asarray(state)\n",
    "        #print(\"gg\")\n",
    "        #print(state[0].shape)\n",
    "        #print(state[0][35:195, :, :])\n",
    "        #print(typeof(state[35:195, :, :]))\n",
    "        state = rgb2gray(state[35:195, :, :])#state[0][35:195, :])#\n",
    "        state = rescale(state, scale=0.5)\n",
    "        state = state[np.newaxis, np.newaxis, :, :]\n",
    "        return torch.tensor(state, device=self.device, dtype=torch.float)\n",
    "    \n",
    "    def exploration_rate(self, t):\n",
    "        if 0 <= t < self.anneal_time:\n",
    "            return self.e_i - t*(self.e_i - self.e_f)/self.anneal_time\n",
    "        elif t >= self.anneal_time:\n",
    "            return self.e_f\n",
    "        elif t < 0:\n",
    "            return self.e_i\n",
    "    \n",
    "    def save(self, t):\n",
    "        save_path = os.path.join(self.ckptdir, 'model-{}'.format(t))\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "    \n",
    "    def load(self):\n",
    "        ckpts = [file for file in os.listdir(self.ckptdir) if 'model' in file]\n",
    "        steps = [int(re.search('\\d+', file).group(0)) for file in ckpts]\n",
    "        \n",
    "        latest_ckpt = ckpts[np.argmax(steps)]\n",
    "        self.t = np.max(steps)\n",
    "        \n",
    "        print(\"Loading checkpoint: {}\".format(latest_ckpt))\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(os.path.join(self.ckptdir, latest_ckpt)))\n",
    "        \n",
    "    def update(self, batch_size):\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        state, action, reward, terminal, next_state = self.retrieve(batch_size)\n",
    "        q = self.model(state).gather(1, action.view(batch_size, 1))\n",
    "        qmax = self.clone_model(next_state).max(dim=1)[0]\n",
    "        \n",
    "        nonterminal_target = reward + self.gamma*qmax\n",
    "        terminal_target = reward\n",
    "        \n",
    "        target = terminal.float()*terminal_target + (~terminal).float()*nonterminal_target\n",
    "    \n",
    "        loss = self.loss(q.view(-1), target)\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "    def play(self, episodes, train=False, load=False, plot=False, render=False, verbose=False):\n",
    "        has_burned_in_yet = False\n",
    "        modthing=0\n",
    "        self.t = 0\n",
    "        metadata = dict(episode=[], reward=[])\n",
    "        \n",
    "        if load:\n",
    "            self.load()\n",
    "\n",
    "        try:\n",
    "            progress_bar = tqdm(range(episodes), unit='episode')\n",
    "            \n",
    "            i = 0\n",
    "            for episode in progress_bar:\n",
    "\n",
    "                state, info = env.reset()\n",
    "                state = self.process(state)\n",
    "                #print(state.shape)\n",
    "                done = False\n",
    "                total_reward = 0\n",
    "\n",
    "                if(render):\n",
    "                    img = plt.imshow(env.render())\n",
    "                while not done:\n",
    "                    modthing += 1\n",
    "                    if render and modthing%100==0:\n",
    "                        img.set_data(env.render())\n",
    "                        display.display(plt.gcf())\n",
    "                        display.clear_output(wait=True)\n",
    "\n",
    "                        \n",
    "                    #print(state.size()[1])\n",
    "                    while state.size()[1] < num_frames:\n",
    "                        action = 1 # Fire\n",
    "                        #observation, reward, terminated, truncated, info\n",
    "                        new_frame, reward, done,truncated, info = env.step(action)\n",
    "                        new_frame = self.process(new_frame)\n",
    "\n",
    "                        state = torch.cat([state, new_frame], 1)\n",
    "                    #print(\"hmm\")\n",
    "                    #print(state.shape)\n",
    "                    \n",
    "                    if train and np.random.uniform() < self.exploration_rate(self.t-burn_in):\n",
    "                        action = np.random.choice(num_actions)\n",
    "\n",
    "                    else:\n",
    "                        action = self.act(state)\n",
    "\n",
    "                    new_frame, reward, done,truncated, info = env.step(action)\n",
    "                    new_frame = self.process(new_frame)\n",
    "\n",
    "                    new_state = torch.cat([state, new_frame], 1)\n",
    "                    new_state = new_state[:, 1:, :, :]\n",
    "                    \n",
    "                    if train:\n",
    "                        reward = torch.tensor([reward], device=self.device, dtype=torch.float)\n",
    "                        action = torch.tensor([action], device=self.device, dtype=torch.long)\n",
    "                        done = torch.tensor([done], device=self.device, dtype=torch.uint8)\n",
    "                        \n",
    "                        self.remember(state, action, reward, done, new_state)\n",
    "\n",
    "                    state = new_state\n",
    "                    total_reward += reward\n",
    "                    self.t += 1\n",
    "                    i += 1\n",
    "                    \n",
    "                    #if not train:\n",
    "                        #time.sleep(0.1)\n",
    "                    \n",
    "                    if train and self.t > burn_in and i > batch_size:\n",
    "\n",
    "                        if self.t % update_interval == 0:\n",
    "                            if not has_burned_in_yet:\n",
    "                                print(\"burn in phase passed, now updating weights\")\n",
    "                                has_burned_in_yet = True\n",
    "                            self.update(batch_size)\n",
    "\n",
    "                        if self.t % clone_interval == 0:\n",
    "                            self.clone()\n",
    "\n",
    "                        if self.t % save_interval == 0:\n",
    "                            self.save(self.t)\n",
    "\n",
    "                    if self.t % 1000 == 0:\n",
    "                        progress_bar.set_description(\"t = {}\".format(self.t))\n",
    "                if episode != None:\n",
    "                    metadata['episode'].append(episode)\n",
    "                if reward != None:\n",
    "                    metadata['reward'].append(total_reward.cpu())\n",
    "\n",
    "                if episode % 50 == 0 and episode != 0:\n",
    "                    avg_return = np.mean(metadata['reward'][-50:])\n",
    "                    print(\"Average return (last 50 episodes): {:.2f}\".format(avg_return))\n",
    "                    print(\"randomly choosing action\",self.exploration_rate(self.t-burn_in)*100,\"percent of the time\")\n",
    "\n",
    "                if plot:\n",
    "                    plt.scatter(metadata['episode'], metadata['reward'])\n",
    "                    plt.xlim(0, episodes)\n",
    "                    plt.xlabel(\"Episode\")\n",
    "                    plt.ylabel(\"Return\")\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(plt.gcf())\n",
    "            \n",
    "            env.close()\n",
    "            return metadata\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            if train:\n",
    "                print(\"Saving model before quitting...\")\n",
    "                self.save(self.t)\n",
    "            \n",
    "            env.close()\n",
    "            return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#env = gym.make(\"ALE/SpaceInvaders-v5\")\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "batch_size = 32\n",
    "update_interval = 4\n",
    "clone_interval = int(1e4)\n",
    "save_interval = int(1e5)\n",
    "frame_skip = None\n",
    "num_frames = 4\n",
    "num_actions = len(env.unwrapped.get_action_meanings())\n",
    "episodes = int(1e5)#5000#\n",
    "memory_depth = 50000\n",
    "epsilon_i = 1\n",
    "epsilon_f = 0.1\n",
    "anneal_time = int(1e6)#episodes*400\n",
    "burn_in = int(5e4)\n",
    "gamma = 0.99\n",
    "learning_rate = 2.5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5993bfc8a97408a81a9e56be32765df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DeepQNetwork(num_frames, num_actions)\n",
    "agent = Agent(model, memory_depth, learning_rate, gamma, epsilon_i, epsilon_f, anneal_time, 'ckpt')\n",
    "\n",
    "metadata = agent.play(episodes, train=True, load=False,plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120],\n",
       " 'reward': [tensor([140.]),\n",
       "  tensor([155.]),\n",
       "  tensor([105.]),\n",
       "  tensor([300.]),\n",
       "  tensor([75.]),\n",
       "  tensor([125.]),\n",
       "  tensor([75.]),\n",
       "  tensor([360.]),\n",
       "  tensor([105.]),\n",
       "  tensor([185.]),\n",
       "  tensor([105.]),\n",
       "  tensor([160.]),\n",
       "  tensor([180.]),\n",
       "  tensor([180.]),\n",
       "  tensor([110.]),\n",
       "  tensor([105.]),\n",
       "  tensor([105.]),\n",
       "  tensor([160.]),\n",
       "  tensor([120.]),\n",
       "  tensor([355.]),\n",
       "  tensor([155.]),\n",
       "  tensor([155.]),\n",
       "  tensor([105.]),\n",
       "  tensor([145.]),\n",
       "  tensor([135.]),\n",
       "  tensor([135.]),\n",
       "  tensor([135.]),\n",
       "  tensor([425.]),\n",
       "  tensor([130.]),\n",
       "  tensor([135.]),\n",
       "  tensor([145.]),\n",
       "  tensor([180.]),\n",
       "  tensor([160.]),\n",
       "  tensor([135.]),\n",
       "  tensor([135.]),\n",
       "  tensor([155.]),\n",
       "  tensor([135.]),\n",
       "  tensor([380.]),\n",
       "  tensor([105.]),\n",
       "  tensor([110.]),\n",
       "  tensor([135.]),\n",
       "  tensor([210.]),\n",
       "  tensor([180.]),\n",
       "  tensor([135.]),\n",
       "  tensor([110.]),\n",
       "  tensor([110.]),\n",
       "  tensor([155.]),\n",
       "  tensor([135.]),\n",
       "  tensor([105.]),\n",
       "  tensor([75.]),\n",
       "  tensor([240.]),\n",
       "  tensor([50.]),\n",
       "  tensor([155.]),\n",
       "  tensor([105.]),\n",
       "  tensor([75.]),\n",
       "  tensor([125.]),\n",
       "  tensor([135.]),\n",
       "  tensor([110.]),\n",
       "  tensor([75.]),\n",
       "  tensor([135.]),\n",
       "  tensor([130.]),\n",
       "  tensor([165.]),\n",
       "  tensor([155.]),\n",
       "  tensor([75.]),\n",
       "  tensor([160.]),\n",
       "  tensor([50.]),\n",
       "  tensor([105.]),\n",
       "  tensor([105.]),\n",
       "  tensor([155.]),\n",
       "  tensor([320.]),\n",
       "  tensor([75.]),\n",
       "  tensor([75.]),\n",
       "  tensor([110.]),\n",
       "  tensor([260.]),\n",
       "  tensor([75.]),\n",
       "  tensor([75.]),\n",
       "  tensor([155.]),\n",
       "  tensor([145.]),\n",
       "  tensor([75.]),\n",
       "  tensor([75.]),\n",
       "  tensor([120.]),\n",
       "  tensor([180.]),\n",
       "  tensor([120.]),\n",
       "  tensor([150.]),\n",
       "  tensor([105.]),\n",
       "  tensor([135.]),\n",
       "  tensor([155.]),\n",
       "  tensor([110.]),\n",
       "  tensor([110.]),\n",
       "  tensor([165.]),\n",
       "  tensor([75.]),\n",
       "  tensor([50.]),\n",
       "  tensor([120.]),\n",
       "  tensor([75.]),\n",
       "  tensor([120.]),\n",
       "  tensor([180.]),\n",
       "  tensor([160.]),\n",
       "  tensor([105.]),\n",
       "  tensor([75.]),\n",
       "  tensor([175.]),\n",
       "  tensor([145.]),\n",
       "  tensor([50.]),\n",
       "  tensor([75.]),\n",
       "  tensor([155.]),\n",
       "  tensor([50.]),\n",
       "  tensor([120.]),\n",
       "  tensor([50.]),\n",
       "  tensor([50.]),\n",
       "  tensor([155.]),\n",
       "  tensor([120.]),\n",
       "  tensor([155.]),\n",
       "  tensor([50.]),\n",
       "  tensor([125.]),\n",
       "  tensor([105.]),\n",
       "  tensor([155.]),\n",
       "  tensor([105.]),\n",
       "  tensor([75.]),\n",
       "  tensor([135.]),\n",
       "  tensor([120.]),\n",
       "  tensor([105.]),\n",
       "  tensor([120.])]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7ea780a62149f5aafa489dc8c6587f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 2.06 MiB is free. Process 23265 has 10.91 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 154.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8053/2669421742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRENDER_WHILE_TRAINING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8053/1443912786.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, episodes, train, load, plot, render, verbose)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0mnew_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8053/1443912786.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8053/3397717805.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# In: (20, 20, 16) Out: (10, 10, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# In: (10, 10, 32) Out: (3200,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# In: (3200,)      Out: (256,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# In: (256,)       Out: (4,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 2.06 MiB is free. Process 23265 has 10.91 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 154.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\", render_mode=\"rgb_array\")\n",
    "env.metadata[\"render_fps\"] = 120\n",
    "RENDER_WHILE_TRAINING = True\n",
    "\n",
    "metadata = agent.play(1, train=False, load=False,render=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    img = plt.imshow(env.render())\n",
    "    while not done:\n",
    "        print(\"hellpo\")\n",
    "        #env.render(\"rgb_array\")\n",
    "        if RENDER_WHILE_TRAINING:\n",
    "            img.set_data(env.render())\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        print(state)\n",
    "        state = agent.process(state)\n",
    "        print(state.shape)\n",
    "        action = agent.act(state)#random.choice([0,1,2,3,4,5])\n",
    "        print(action)\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "        if terminated or truncated:\n",
    "            state, info = env.reset()\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Displme",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
